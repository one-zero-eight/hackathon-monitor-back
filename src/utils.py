import logging
import re
from pathlib import Path

import httpx
import yaml
from fastapi.routing import APIRoute

from src.config import settings, Target
from src.exceptions import NotEnoughPermissionsException
from src.repositories.alerts import AlertRepository
from src.schemas.tokens import VerificationResult
from src.storages.monitoring.config import Alert, settings as monitoring_settings


async def setup_repositories():
    from src.repositories.users import UserRepository
    from src.repositories.pg import PgRepository
    from src.storages.sqlalchemy import SQLAlchemyStorage
    from src.repositories.smtp import SMTPRepository
    from src.app.dependencies import Dependencies

    # ------------------- Repositories Dependencies -------------------
    storage = SQLAlchemyStorage.from_url(settings.DB_URL.get_secret_value())
    user_repository = UserRepository(storage)
    alert_repository = AlertRepository(storage)
    # TODO: Add target repository
    target = list(settings.TARGETS.values())[0]

    target_storage = SQLAlchemyStorage.from_url(target.DB_URL.get_secret_value())
    pg_stat = PgRepository(target_storage)

    Dependencies.set_storage(storage)
    Dependencies.set_user_repository(user_repository)
    Dependencies.set_pg_stat_repository(pg_stat)
    Dependencies.set_alert_repository(alert_repository)

    if settings.SMTP_ENABLED:
        smtp_repository = SMTPRepository()
        Dependencies.set_smtp_repository(smtp_repository)

    # await storage.create_all()


def generate_unique_operation_id(route: APIRoute) -> str:
    # Better names for operationId in OpenAPI schema.
    # It is needed because clients generate code based on these names.
    # Requires pair (tag name + function name) to be unique.
    # See fastapi.utils:generate_unique_id (default implementation).
    operation_id = f"{route.tags[0]}_{route.name}".lower()
    operation_id = re.sub(r"\W+", "_", operation_id)
    return operation_id


async def generate_prometheus_alert_rules(alerts: dict[str, Alert], path: Path):
    # Generate config
    rules = []
    for alias, alert in alerts.items():
        rules.append(
            {
                "alert": alias,
                "expr": alert.rule.expr,
                "for": alert.rule.for_,
                "annotations": alert.rule.annotations,
            }
        )
    rules_config = {"groups": [{"name": "db", "rules": rules}]}

    # Dump to string and check if file has changed
    rules_config = yaml.safe_dump(rules_config, sort_keys=False, allow_unicode=True)
    rules_config = "# This file is generated by the application. Do not edit it manually.\n\n" + rules_config
    if path.exists() and path.read_text() == rules_config:
        logging.info("Prometheus alert rules has not changed")
        return False

    # Write to file and reload Prometheus
    logging.warning("Prometheus alert rules has changed")
    path.write_text(rules_config)
    return True


async def generate_prometheus_scrape_configs(targets: dict[str, Target], path: Path):
    # Generate scrape configs
    scrape_static_configs = []
    for alias, target in targets.items():
        scrape_static_configs.append(
            {
                "targets": [f"{target.SSH_HOST}:9187", f"{target.SSH_HOST}:9100"],
                "labels": {
                    "target": alias,
                },
            }
        )
    scrape_configs = [
        {
            "job_name": "db",
            "static_configs": scrape_static_configs,
        }
    ]

    # Read old config to preserve other options
    if path.exists():
        old_config = yaml.safe_load(path.read_text())
    else:
        old_config = {}

    # Merge old and new configs
    new_config = {**old_config, "scrape_configs": scrape_configs}

    # Dump to string and check if file has changed
    new_config = yaml.safe_dump(new_config, sort_keys=False, allow_unicode=True)
    new_config = (
        "# The 'scrape_configs' option is generated by the application. Do not edit it manually.\n\n" + new_config
    )
    if path.exists() and path.read_text() == new_config:
        logging.info("Prometheus scrape configs has not changed")
        return False

    # Write to file and reload Prometheus
    logging.warning("Prometheus scrape configs has changed")
    path.write_text(new_config)
    return True


async def generate_prometheus_configs():
    need_reload_1 = await generate_prometheus_alert_rules(
        alerts=monitoring_settings.alerts,
        path=Path(settings.PROMETHEUS.ALERT_RULES_PATH),
    )
    need_reload_2 = await generate_prometheus_scrape_configs(
        targets=settings.TARGETS,
        path=Path(settings.PROMETHEUS.PROMETHEUS_CONFIG_PATH),
    )
    if need_reload_1 or need_reload_2:
        logging.warning("Reloading Prometheus")
        async with httpx.AsyncClient() as client:
            await client.post(settings.PROMETHEUS.URL + "/-/reload")


def permission_check(_verification: VerificationResult, target: Target):
    if (not _verification.user_id) or (_verification.user_id not in target.ADMINS):
        raise NotEnoughPermissionsException()
